{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014ab149",
   "metadata": {},
   "source": [
    "## ì›Œí¬í”Œë¡œìš° ìš”ì•½\n",
    "\n",
    "[ì„ í–‰ì‘ì—…] KoBARTë¡œ ê¸°ì‚¬ ë³¸ë¬¸ì˜ [ìƒì„± ìš”ì•½ë¬¸]ì„ ë¯¸ë¦¬ ì¤€ë¹„í•©ë‹ˆë‹¤.  \n",
    "[ë°ì´í„° êµ¬ì¶•] [ì •ìƒ ì œëª©]+[ìƒì„± ìš”ì•½ë¬¸] / [ë‚šì‹œì„± ì œëª©] + [ìƒì„± ìš”ì•½ë¬¸]ì„ í˜ì–´ë¡œ ë¬¶ì–´ ëŒ€ì¡° í•™ìŠµìš© ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.  \n",
    "[ëª¨ë¸ í•™ìŠµ] KoSimCSE ëª¨ë¸ì„ ContrastiveLossë¡œ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤.  \n",
    "[í‰ê°€] í•™ìŠµëœ ëª¨ë¸ë¡œ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê³  ì„ê³„ê°’(Threshold)ì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c2ced",
   "metadata": {},
   "source": [
    "## 1ë‹¨ê³„: ì„ í–‰ ì‘ì—… - KoBART ìš”ì•½ ëª¨ë¸ (ê°€ì •)\n",
    "\n",
    "ë³¸ ë…¸íŠ¸ë¶ì€ 1ë‹¨ê³„ê°€ ì´ë¯¸ ì™„ë£Œë˜ì—ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. \n",
    "(ë³´ìœ í•œ <ìš”ì•½ë¬¸ ìƒì„± ë°ì´í„°>(B)ë¡œ KoBART ëª¨ë¸ì´ ì´ë¯¸ íŒŒì¸íŠœë‹ë˜ì—ˆìŠµë‹ˆë‹¤.)\n",
    "\n",
    "ì´ KoBART ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, <ë‚šì‹œì„± ë‰´ìŠ¤ ë°ì´í„°>(A)ì˜ ëª¨ë“  ë³¸ë¬¸ì— ëŒ€í•œ [ìƒì„±ëœ ìš”ì•½ë¬¸]ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4aa164",
   "metadata": {},
   "source": [
    "## 2ë‹¨ê³„: KoSimCSE í•™ìŠµìš© ë°ì´í„°ì…‹ êµ¬ì¶• \n",
    "KoSimCSE ëª¨ë¸ì„ 'ì§€ë„ í•™ìŠµ(Supervised)' ë°©ì‹ì˜ ëŒ€ì¡° í•™ìŠµìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "Positive Pair (ì¼ì¹˜, ë ˆì´ë¸” 1.0)\n",
    "ì…ë ¥ 1 (text1): <ë‚šì‹œì„± ë‰´ìŠ¤ ë°ì´í„°>(A.i)ì˜ [ì •ìƒ ê¸°ì‚¬ ì œëª©]\n",
    "ì…ë ¥ 2 (text2): 1ë‹¨ê³„ì—ì„œ ìƒì„±í•œ í•´ë‹¹ ê¸°ì‚¬ì˜ [ìƒì„±ëœ ìš”ì•½ë¬¸]\n",
    "\n",
    "Negative Pair (ë¶ˆì¼ì¹˜, ë ˆì´ë¸” 0.0)\n",
    "ì…ë ¥ 1 (text1): <ë‚šì‹œì„± ë‰´ìŠ¤ ë°ì´í„°>(A.ii)ì˜ [ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê¸°ì‚¬ ì œëª©]\n",
    "ì…ë ¥ 2 (text2): 1ë‹¨ê³„ì—ì„œ ìƒì„±í•œ í•´ë‹¹ ê¸°ì‚¬ì˜ [ìƒì„±ëœ ìš”ì•½ë¬¸]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43313fbd",
   "metadata": {},
   "source": [
    "## 3ë‹¨ê³„: KoSimCSE ëª¨ë¸ êµ¬ì„± ë° íŒŒì¸íŠœë‹\n",
    "sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì„±í•˜ê³  í•™ìŠµì‹œí‚µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d107c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 3.1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Jupyter/Colab í™˜ê²½)\n",
    "# %pip install sentence-transformers torch\n",
    "\n",
    "#ê¸°íƒ€ í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# %pip install datasets\n",
    "# %pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 3.2. ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cee925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 6ê°œì˜ í•™ìŠµ ì˜ˆì‹œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 3.3. í•™ìŠµ ë°ì´í„° ì •ì˜ (ì˜ˆì‹œ)\n",
    "# 2ë‹¨ê³„ì—ì„œ ì„¤ëª…í•œ (text1, text2, label) í˜•ì‹ì˜ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
    "# ì°¸ê³ : ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì´ ë¦¬ìŠ¤íŠ¸ì— ìˆ˜ì²œ~ìˆ˜ë§Œ ê±´ì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "# [ (text1: ê¸°ì‚¬ ì œëª©), (text2: ë³¸ë¬¸ ìš”ì•½ë¬¸), (label: 1.0=ì¼ì¹˜, 0.0=ë¶ˆì¼ì¹˜) ]\n",
    "train_data_list = [\n",
    "    # ì˜ˆì‹œ 1: ê¹€ë´‰ì§„ ëŒ€í‘œ (ì‚¬ìš©ì ì œê³µ ë°ì´í„° ê¸°ë°˜)\n",
    "    (\"40ì–µë‹¬ëŸ¬ ë”œ ì£¼ì¸ê³µ ê¹€ë´‰ì§„ \\\"êµ­ë‚´ì„œ í¼ì¡ë‹¤ ì£½ê³ ì‹¶ì§€ ì•Šì•˜ë‹¤\\\"\", \n",
    "     \"DHê°€ ê¸°ì—…ê°€ì¹˜ë¥¼ ì•½ 4ì¡° 8000ì–µ ì›ìœ¼ë¡œ í‰ê°€í•œ ìš°ì•„í•œí˜•ì œë“¤ì˜ ê¹€ ëŒ€í‘œëŠ” êµ­ë‚´ ìŠ¤íƒ€íŠ¸ì—… ì‚¬ìƒ ìµœëŒ€ ê·œëª¨ì˜ M&A ì´í›„ í•©ì‘ë²•ì¸ ìš°ì•„DHì•„ì‹œì•„ì˜ ì±…ì„ìê°€ ëœë‹¤.\", \n",
    "     1.0), # Positive Pair\n",
    "    (\"â€˜ë¯¼ì¡±â€™ ë²„ë¦¬ê³  ë…ì¼ íƒí–ˆë‹¤? 40ì–µë‹¬ëŸ¬ ê¹€ë´‰ì§„ ëŒ€í‘œì˜ ì¶©ê²©ì  ì„ íƒ\", \n",
    "     \"DHê°€ ê¸°ì—…ê°€ì¹˜ë¥¼ ì•½ 4ì¡° 8000ì–µ ì›ìœ¼ë¡œ í‰ê°€í•œ ìš°ì•„í•œí˜•ì œë“¤ì˜ ê¹€ ëŒ€í‘œëŠ” êµ­ë‚´ ìŠ¤íƒ€íŠ¸ì—… ì‚¬ìƒ ìµœëŒ€ ê·œëª¨ì˜ M&A ì´í›„ í•©ì‘ë²•ì¸ ìš°ì•„DHì•„ì‹œì•„ì˜ ì±…ì„ìê°€ ëœë‹¤.\", \n",
    "     0.0), # Negative Pair\n",
    "    \n",
    "    # ì˜ˆì‹œ 2: ë¶€ë™ì‚° (ì¶”ê°€ ì˜ˆì‹œ)\n",
    "    (\"ì„œìš¸ ì•„íŒŒíŠ¸ ê±°ë˜ëŸ‰ 3ê°œì›” ì—°ì† ê°ì†Œ... ê¸ˆë¦¬ ì˜í–¥ 'ëšœë ·'\", \n",
    "     \"ê¸ˆë¦¬ ì¸ìƒê³¼ ëŒ€ì¶œ ê·œì œì˜ ì˜í–¥ìœ¼ë¡œ ë§¤ìˆ˜ ì‹¬ë¦¬ê°€ ìœ„ì¶•ë˜ë©´ì„œ, ì„œìš¸ ì•„íŒŒíŠ¸ ì›”ê°„ ê±°ë˜ëŸ‰ì´ 3ê°œì›” ì—°ì† ê°ì†Œí•˜ë©° ì‹œì¥ ì•ˆì •í™” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤.\", \n",
    "     1.0), # Positive Pair\n",
    "    (\"ì„œìš¸ ì•„íŒŒíŠ¸ 'í­ë½' ì‹œì‘ëë‹¤! ì§€ê¸ˆ ë‹¹ì¥ ì§‘ íŒ”ì•„ì•¼ í•˜ëŠ” ì´ìœ \", \n",
    "     \"ê¸ˆë¦¬ ì¸ìƒê³¼ ëŒ€ì¶œ ê·œì œì˜ ì˜í–¥ìœ¼ë¡œ ë§¤ìˆ˜ ì‹¬ë¦¬ê°€ ìœ„ì¶•ë˜ë©´ì„œ, ì„œìš¸ ì•„íŒŒíŠ¸ ì›”ê°„ ê±°ë˜ëŸ‰ì´ 3ê°œì›” ì—°ì† ê°ì†Œí•˜ë©° ì‹œì¥ ì•ˆì •í™” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤.\", \n",
    "     0.0), # Negative Pair\n",
    "    \n",
    "    # ì˜ˆì‹œ 3: IT/ê¸°ìˆ  (ì¶”ê°€ ì˜ˆì‹œ)\n",
    "    (\"ê³¼ê¸°ë¶€, ì°¨ì„¸ëŒ€ AI ë°˜ë„ì²´ ê°œë°œì— 5ë…„ê°„ 1ì¡°ì› íˆ¬ì…\", \n",
    "     \"ì •ë¶€ê°€ ê¸€ë¡œë²Œ AI ì‹œì¥ ê²½ìŸë ¥ í™•ë³´ë¥¼ ìœ„í•´, í–¥í›„ 5ë…„ê°„ 1ì¡° ì› ê·œëª¨ì˜ ì˜ˆì‚°ì„ íˆ¬ì…í•˜ì—¬ ì‹œìŠ¤í…œ ë°˜ë„ì²´ì™€ AI ê¸°ìˆ ì„ ìœµí•©í•œ ì°¨ì„¸ëŒ€ ë°˜ë„ì²´ ê°œë°œì„ ì¶”ì§„í•œë‹¤.\", \n",
    "     1.0), # Positive Pair\n",
    "    (\"AIê°€ ì¸ê°„ ì¼ìë¦¬ ëª¨ë‘ ë¹¼ì•—ëŠ”ë‹¤... ì •ë¶€ì˜ ì¶©ê²©ì ì¸ '1ì¡°ì›' ê³„íš\", \n",
    "     \"ì •ë¶€ê°€ ê¸€ë¡œë²Œ AI ì‹œì¥ ê²½ìŸë ¥ í™•ë³´ë¥¼ ìœ„í•´, í–¥í›„ 5ë…„ê°„ 1ì¡° ì› ê·œëª¨ì˜ ì˜ˆì‚°ì„ íˆ¬ì…í•˜ì—¬ ì‹œìŠ¤í…œ ë°˜ë„ì²´ì™€ AI ê¸°ìˆ ì„ ìœµí•©í•œ ì°¨ì„¸ëŒ€ ë°˜ë„ì²´ ê°œë°œì„ ì¶”ì§„í•œë‹¤.\", \n",
    "     0.0)  # Negative Pair\n",
    "]\n",
    "\n",
    "print(f\"ì´ {len(train_data_list)}ê°œì˜ í•™ìŠµ ì˜ˆì‹œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8800708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ 'BM-K/KoSimCSE-roberta-multitask' ë¡œë“œ ë° '[CLS] í’€ë§' ì ìš© ì™„ë£Œ.\n",
      "ì‚¬ìš© ì¥ì¹˜: cpu\n",
      "--- (ì´ì œ 'Creating a new one...' ê²½ê³ ê°€ ëœ¨ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤) ---\n"
     ]
    }
   ],
   "source": [
    "# 3.4.0. í•„ìš”í•œ ëª¨ë“ˆ ì¶”ê°€ ì„í¬íŠ¸\n",
    "from sentence_transformers import models\n",
    "\n",
    "# 3.4.1. ì‚¬ìš©í•  KoSimCSE ëª¨ë¸ ì´ë¦„ (ì‚¬ìš©ìë‹˜ì´ ì°¾ìœ¼ì‹  ëª¨ë¸)\n",
    "model_name = 'BM-K/KoSimCSE-roberta-multitask'\n",
    "\n",
    "# 3.4.2. CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 3.4.3. SentenceTransformer ëª¨ë¸ ìˆ˜ë™ ì¡°ë¦½\n",
    "try:\n",
    "    # 1. 'ì—”ì§„' (ê¸°ë³¸ Transformer ëª¨ë¸) ë¡œë“œ\n",
    "    word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "    # 2. 'í’€ë§ ë ˆì´ì–´' ì •ì˜ (ì´ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤!)\n",
    "    # SimCSEëŠ” ë³´í†µ [CLS] í† í°ì˜ ì„ë² ë”©ì„ ë¬¸ì¥ ë²¡í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode='cls' # 'mean'ì´ ì•„ë‹Œ 'cls'ë¡œ ëª…ì‹œì  ì§€ì •\n",
    "    )\n",
    "\n",
    "    # 3. ë‘ ëª¨ë“ˆì„ ê²°í•©í•˜ì—¬ ìµœì¢… SentenceTransformer ëª¨ë¸ ìƒì„±\n",
    "    model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device=device)\n",
    "    \n",
    "    print(f\"ëª¨ë¸ '{model_name}' ë¡œë“œ ë° '[CLS] í’€ë§' ì ìš© ì™„ë£Œ.\")\n",
    "    print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "    print(\"--- (ì´ì œ 'Creating a new one...' ê²½ê³ ê°€ ëœ¨ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤) ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"Hugging Face Hubì— ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€, ëª¨ë¸ ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc9d69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 6ê°œì˜ InputExample ìƒì„± ì™„ë£Œ\n",
      "\n",
      "--- ì²« ë²ˆì§¸ í•™ìŠµ ì˜ˆì‹œ --- \n",
      "Text 1: 40ì–µë‹¬ëŸ¬ ë”œ ì£¼ì¸ê³µ ê¹€ë´‰ì§„ \"êµ­ë‚´ì„œ í¼ì¡ë‹¤ ì£½ê³ ì‹¶ì§€ ì•Šì•˜ë‹¤\"\n",
      "Text 2: DHê°€ ê¸°ì—…ê°€ì¹˜ë¥¼ ì•½ 4ì¡° 8000ì–µ ì›ìœ¼ë¡œ í‰ê°€í•œ ìš°ì•„í•œí˜•ì œë“¤ì˜ ê¹€ ëŒ€í‘œëŠ” êµ­ë‚´ ìŠ¤íƒ€íŠ¸ì—… ì‚¬ìƒ ìµœëŒ€ ê·œëª¨ì˜ M&A ì´í›„ í•©ì‘ë²•ì¸ ìš°ì•„DHì•„ì‹œì•„ì˜ ì±…ì„ìê°€ ëœë‹¤.\n",
      "Label: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 3.5. í•™ìŠµ ë°ì´í„°ì…‹ í˜•ì‹ ë³€í™˜ (InputExample)\n",
    "# sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ContrastiveLossëŠ” InputExample í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
    "# ì—¬ê¸°ì„œ texts ë¦¬ìŠ¤íŠ¸ì—ëŠ” [text1, text2]ê°€, labelì—ëŠ” 0.0 ë˜ëŠ” 1.0ì´ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n",
    "\n",
    "# (ì´ì „ 3.3. ì…€ì—ì„œ train_data_listê°€ ì •ì˜ë˜ì—ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.)\n",
    "\n",
    "train_examples = []\n",
    "for data in train_data_list:\n",
    "    text1 = data[0]\n",
    "    text2 = data[1]\n",
    "    label = float(data[2])\n",
    "    train_examples.append(InputExample(texts=[text1, text2], label=label))\n",
    "\n",
    "print(f\"ì´ {len(train_examples)}ê°œì˜ InputExample ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì˜ˆì‹œ í™•ì¸\n",
    "if train_examples:\n",
    "    print(\"\\n--- ì²« ë²ˆì§¸ í•™ìŠµ ì˜ˆì‹œ --- \")\n",
    "    print(f\"Text 1: {train_examples[0].texts[0]}\")\n",
    "    print(f\"Text 2: {train_examples[0].texts[1]}\")\n",
    "    print(f\"Label: {train_examples[0].label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bbf7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader ë° ContrastiveLoss ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "#-- 3.6. í•™ìŠµ ì„¤ì • (DataLoader ë° Contrastive Loss)\n",
    "# DataLoader: í•™ìŠµ ë°ì´í„°ë¥¼ ë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ëª¨ë¸ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "# ContrastiveLoss: í”„ë¡œì íŠ¸ ê³„íš 5.Bì—ì„œ ì œì•ˆí•œ ëŒ€ì¡° í•™ìŠµ ì†ì‹¤ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "# label=1.0 (Positive) í˜ì–´ëŠ” ì„ë² ë”© ê±°ë¦¬ë¥¼ ê°€ê¹ê²Œ (0ì— ê°€ê¹ê²Œ) ë§Œë“­ë‹ˆë‹¤.\n",
    "# label=0.0 (Negative) í˜ì–´ëŠ” ì„ë² ë”© ê±°ë¦¬ë¥¼ margin ê°’ë³´ë‹¤ ë©€ê²Œ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "# (ì‹¤ì œ ë°ì´í„°ëŠ” ë§¤ìš° í¬ë¯€ë¡œ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ 16, 32 ë“±ìœ¼ë¡œ ì„¤ì •)\n",
    "# (ì˜ˆì‹œ ë°ì´í„°ëŠ” 6ê°œë¿ì´ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” 2ë¡œ ì‘ê²Œ ì„¤ì •)\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "\n",
    "# Loss í•¨ìˆ˜ ì •ì˜: ContrastiveLoss\n",
    "# (3.4ì—ì„œ 'model' ë³€ìˆ˜ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆë‹¤ê³  ê°€ì •)\n",
    "# margin: Negative Pairê°€ ê°€ì ¸ì•¼ í•  ìµœì†Œ ê±°ë¦¬ (ê¸°ë³¸ê°’ 0.5)\n",
    "train_loss = losses.ContrastiveLoss(model=model, margin=0.5) \n",
    "\n",
    "print(\"DataLoader ë° ContrastiveLoss ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7baefc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹œì‘... (Epochs: 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56928f7540c449198e63e790054f5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9\n",
      "  Number of trainable parameters = 110,618,112\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "2025-11-03 15:26:12 - Save model to ./my-finetuned-simcse-model\n",
      "Configuration saved in ./my-finetuned-simcse-model/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2.5038, 'train_samples_per_second': 7.189, 'train_steps_per_second': 3.594, 'train_loss': 0.0008616057328051991, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./my-finetuned-simcse-model/model.safetensors\n",
      "tokenizer config file saved in ./my-finetuned-simcse-model/tokenizer_config.json\n",
      "Special tokens file saved in ./my-finetuned-simcse-model/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! './my-finetuned-simcse-model' ê²½ë¡œì— ì €ì¥ë¨.\n",
      "\n",
      "--- ğŸš€ í•™ìŠµ ìµœì¢… ìš”ì•½ ---\n",
      "  ì´ í•™ìŠµ ì‹œê°„  : 3.11 ì´ˆ\n",
      "  (ì—í¬í¬ë³„ LossëŠ” í•™ìŠµ ì¤‘ ì¶œë ¥ëœ INFO ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#-- 3.7. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "# ì´ì œ model.fit()ì„ í˜¸ì¶œí•˜ì—¬ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•©ë‹ˆë‹¤. \n",
    "# í•™ìŠµì´ ì™„ë£Œë˜ë©´ ì§€ì •ëœ ê²½ë¡œì— íŒŒì¸íŠœë‹ëœ ëª¨ë¸ íŒŒì¼ë“¤ì´ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "\n",
    "# (NEW) 1. ë¡œê¹… ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import logging\n",
    "import time  # (NEW) ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "\n",
    "# (NEW) 2. ë¡œê¹… ì„¤ì • (INFO ë ˆë²¨)\n",
    "# model.fit()ì´ INFO ë ˆë²¨ì˜ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "# (ì´ ì½”ë“œëŠ” ë…¸íŠ¸ë¶ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤)\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "num_epochs = 3 # ì—í¬í¬ (ì‹¤ì œ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œëŠ” 1~3 ì‚¬ì´ë¡œ ì¡°ì ˆ)\n",
    "warmup_steps = 1 # ì˜ˆì‹œ ë°ì´í„°ê°€ ë§¤ìš° ì‘ìœ¼ë¯€ë¡œ 1ë¡œ ì„¤ì • (ì‹¤ì œë¡œëŠ” 100-500)\n",
    "model_save_path = './my-finetuned-simcse-model' # í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë  ê²½ë¡œ\n",
    "\n",
    "print(f\"ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹œì‘... (Epochs: {num_epochs})\")\n",
    "\n",
    "# (NEW) í•™ìŠµ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "start_time = time.time()\n",
    "\n",
    "# ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "# (3.4ì˜ 'model' ë³€ìˆ˜ì™€ 3.6ì˜ 'train_loss' ë³€ìˆ˜ë¥¼ ì‚¬ìš©)\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path,\n",
    "          show_progress_bar=False)\n",
    "\n",
    "# (NEW) ì¢…ë£Œ ì‹œê°„ ê¸°ë¡ ë° ì´ ì‹œê°„ ê³„ì‚°\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nëª¨ë¸ í•™ìŠµ ì™„ë£Œ! '{model_save_path}' ê²½ë¡œì— ì €ì¥ë¨.\")\n",
    "\n",
    "# (NEW) 5. í•™ìŠµ ê²°ê³¼(ì‹œê°„)ë¥¼ ê°€ì‹œì„± ì¢‹ê²Œ ì¶œë ¥\n",
    "print(\"\\n--- ğŸš€ í•™ìŠµ ìµœì¢… ìš”ì•½ ---\")\n",
    "print(f\"  ì´ í•™ìŠµ ì‹œê°„  : {total_time:.2f} ì´ˆ\")\n",
    "print(\"  (ì—í¬í¬ë³„ LossëŠ” í•™ìŠµ ì¤‘ ì¶œë ¥ëœ INFO ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”)\")\n",
    "print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757ada0",
   "metadata": {},
   "source": [
    "## 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ë° ì„ê³„ê°’(Threshold) ì„¤ì •\n",
    "í•™ìŠµëœ ëª¨ë¸(í˜¹ì€ ì €ì¥ëœ ëª¨ë¸)ì„ ì‚¬ìš©í•˜ì—¬ 'ì •ìƒ'ê³¼ 'ë‚šì‹œì„±'ì„ ì–¼ë§ˆë‚˜ ì˜ êµ¬ë¶„í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde64343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 19:49:35 - Use pytorch device_name: mps\n",
      "2025-11-03 19:49:35 - Load pretrained SentenceTransformer: ./my-finetuned-simcse-model\n",
      "loading configuration file ./my-finetuned-simcse-model/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./my-finetuned-simcse-model/model.safetensors\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„ë² ë”© ì¤‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056d0240066748c5bab37d72164d4fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df395abb7ea4d06864b711f1625b8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f05282c8b4d4f50838cf564872c04c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8dbda281594296abc73d7369173ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ ---\n",
      "[í…ŒìŠ¤íŠ¸ 1: ì •ìƒ ê¸°ì‚¬ Pair] ìœ ì‚¬ë„: 0.9073\n",
      "[í…ŒìŠ¤íŠ¸ 2: ë‚šì‹œì„± ê¸°ì‚¬ Pair] ìœ ì‚¬ë„: 0.7710\n"
     ]
    }
   ],
   "source": [
    "#-- 4.1. í•™ìŠµëœ ëª¨ë¸ë¡œ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸\n",
    "#ì¤‘ìš”: ì´ ë‹¨ê³„ì—ì„œëŠ” í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šì€ ë³„ë„ì˜ í‰ê°€(validation/test) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì—¬ê¸°ì„œëŠ” 3.7ì—ì„œ í•™ìŠµì´ ì™„ë£Œëœ model ê°ì²´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬, ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "# (ì„ íƒì‚¬í•­) ë§Œì•½ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¬ì‹œì‘í–ˆë‹¤ë©´, ì €ì¥ëœ ëª¨ë¸ì„ ì´ë ‡ê²Œ ë¡œë“œí•©ë‹ˆë‹¤:\n",
    "model = SentenceTransformer(model_save_path)\n",
    "print(\"ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜ ---\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ì˜ë¯¸ê°€ í†µí•˜ëŠ” Pair (Positive)\n",
    "test_headline_1 = \"ê¹€ë´‰ì§„, 40ì–µë‹¬ëŸ¬ ë”œë¡œ ì•„ì‹œì•„ 11ê°œêµ­ ì´ê´„\"\n",
    "test_summary_1 = \"ìš°ì•„í•œí˜•ì œë“¤ ê¹€ë´‰ì§„ ëŒ€í‘œê°€ DHì™€ì˜ M&Aë¡œ 4.8ì¡° ê°€ì¹˜ë¥¼ ì¸ì •ë°›ê³ , í•©ì‘ë²•ì¸ 'ìš°ì•„DHì•„ì‹œì•„'ì˜ ì±…ì„ìê°€ ë˜ì—ˆë‹¤.\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ì˜ë¯¸ê°€ ì–´ê¸‹ë‚˜ëŠ” Pair (Negative - Clickbait)\n",
    "test_headline_2 = \"ê¹€ë´‰ì§„ ëŒ€í‘œ, íšŒì‚¬ ë§¤ê° í›„ ëŒì—° ì ì ... 'ì¶©ê²©'\"\n",
    "test_summary_2 = \"ìš°ì•„í•œí˜•ì œë“¤ ê¹€ë´‰ì§„ ëŒ€í‘œê°€ DHì™€ì˜ M&Aë¡œ 4.8ì¡° ê°€ì¹˜ë¥¼ ì¸ì •ë°›ê³ , í•©ì‘ë²•ì¸ 'ìš°ì•„DHì•„ì‹œì•„'ì˜ ì±…ì„ìê°€ ë˜ì—ˆë‹¤.\"\n",
    "\n",
    "# --- ê° ë¬¸ì¥ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ ---\n",
    "# (3.7ì—ì„œ í•™ìŠµëœ 'model' ë³€ìˆ˜ë¥¼ ì‚¬ìš©)\n",
    "print(\"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„ë² ë”© ì¤‘...\")\n",
    "embedding1 = model.encode(test_headline_1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(test_summary_1, convert_to_tensor=True)\n",
    "\n",
    "embedding3 = model.encode(test_headline_2, convert_to_tensor=True)\n",
    "embedding4 = model.encode(test_summary_2, convert_to_tensor=True)\n",
    "\n",
    "# --- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ---\n",
    "cos_sim_1 = util.cos_sim(embedding1, embedding2)[0][0]\n",
    "cos_sim_2 = util.cos_sim(embedding3, embedding4)[0][0]\n",
    "\n",
    "print(\"\\n--- ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ ---\")\n",
    "print(f\"[í…ŒìŠ¤íŠ¸ 1: ì •ìƒ ê¸°ì‚¬ Pair] ìœ ì‚¬ë„: {cos_sim_1:.4f}\")\n",
    "print(f\"[í…ŒìŠ¤íŠ¸ 2: ë‚šì‹œì„± ê¸°ì‚¬ Pair] ìœ ì‚¬ë„: {cos_sim_2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60dfd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. ê°€ìƒ í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ ---\n",
      "--- 2. ì„ë² ë”© ë° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘... ---\n",
      "ê³„ì‚°ëœ ìœ ì‚¬ë„ ê°’: [0.807  0.9616 0.6899 0.5688]\n",
      "ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸”: [1, 1, 0, 0]\n",
      "--- 3. ìµœì ì˜ F1-Score ê¸°ì¤€ ì„ê³„ê°’ íƒìƒ‰ ì¤‘... ---\n",
      "\n",
      "--- 4. íƒìƒ‰ ê²°ê³¼ ---\n",
      "ìµœì ì˜ F1-Score: 1.0000\n",
      "ì´ë•Œì˜ ì„ê³„ê°’(Threshold): 0.69\n"
     ]
    }
   ],
   "source": [
    "# 4.2. ìµœì ì˜ ì„ê³„ê°’(Threshold) ì°¾ê¸° (ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. ê°€ìƒì˜ í‰ê°€(Test) ë°ì´í„°ì…‹ ì •ì˜ ---\n",
    "# (ì‹¤ì œë¡œëŠ” í•™ìŠµ(train) ë°ì´í„°ì™€ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë³„ë„ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤)\n",
    "\n",
    "test_pairs = [\n",
    "    # Positive (ì¼ì¹˜, 1) ì˜ˆì‹œ 2ê°œ\n",
    "    (\"ê¹€ë´‰ì§„, 40ì–µë‹¬ëŸ¬ ë”œë¡œ ì•„ì‹œì•„ 11ê°œêµ­ ì´ê´„\", \n",
    "     \"ìš°ì•„í•œí˜•ì œë“¤ ê¹€ë´‰ì§„ ëŒ€í‘œê°€ DHì™€ì˜ M&Aë¡œ 4.8ì¡° ê°€ì¹˜ë¥¼ ì¸ì •ë°›ê³ , í•©ì‘ë²•ì¸ 'ìš°ì•„DHì•„ì‹œì•„'ì˜ ì±…ì„ìê°€ ë˜ì—ˆë‹¤.\"),\n",
    "    (\"ì„œìš¸ ì•„íŒŒíŠ¸ ê±°ë˜ëŸ‰ 3ê°œì›” ì—°ì† ê°ì†Œ... ê¸ˆë¦¬ ì˜í–¥ 'ëšœë ·'\",\n",
    "     \"ê¸ˆë¦¬ ì¸ìƒê³¼ ëŒ€ì¶œ ê·œì œì˜ ì˜í–¥ìœ¼ë¡œ ë§¤ìˆ˜ ì‹¬ë¦¬ê°€ ìœ„ì¶•ë˜ë©´ì„œ, ì„œìš¸ ì•„íŒŒíŠ¸ ì›”ê°„ ê±°ë˜ëŸ‰ì´ 3ê°œì›” ì—°ì† ê°ì†Œí•˜ë©° ì‹œì¥ ì•ˆì •í™” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤.\"),\n",
    "    \n",
    "    # Negative (ë¶ˆì¼ì¹˜, 0) ì˜ˆì‹œ 2ê°œ\n",
    "    (\"ê¹€ë´‰ì§„ ëŒ€í‘œ, íšŒì‚¬ ë§¤ê° í›„ ëŒì—° ì ì ... 'ì¶©ê²©'\",\n",
    "     \"ìš°ì•„í•œí˜•ì œë“¤ ê¹€ë´‰ì§„ ëŒ€í‘œê°€ DHì™€ì˜ M&Aë¡œ 4.8ì¡° ê°€ì¹˜ë¥¼ ì¸ì •ë°›ê³ , í•©ì‘ë²•ì¸ 'ìš°ì•„DHì•„ì‹œì•„'ì˜ ì±…ì„ìê°€ ë˜ì—ˆë‹¤.\"),\n",
    "    (\"ì„œìš¸ ì•„íŒŒíŠ¸ 'í­ë½' ì‹œì‘ëë‹¤! ì§€ê¸ˆ ë‹¹ì¥ ì§‘ íŒ”ì•„ì•¼ í•˜ëŠ” ì´ìœ \",\n",
    "     \"ê¸ˆë¦¬ ì¸ìƒê³¼ ëŒ€ì¶œ ê·œì œì˜ ì˜í–¥ìœ¼ë¡œ ë§¤ìˆ˜ ì‹¬ë¦¬ê°€ ìœ„ì¶•ë˜ë©´ì„œ, ì„œìš¸ ì•„íŒŒíŠ¸ ì›”ê°„ ê±°ë˜ëŸ‰ì´ 3ê°œì›” ì—°ì† ê°ì†Œí•˜ë©° ì‹œì¥ ì•ˆì •í™” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤.\")\n",
    "]\n",
    "\n",
    "# ìœ„ test_pairsì— 1:1ë¡œ ëŒ€ì‘ë˜ëŠ” ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸”\n",
    "ground_truth_labels = [\n",
    "    1,  # Positive\n",
    "    1,  # Positive\n",
    "    0,  # Negative\n",
    "    0   # Negative\n",
    "]\n",
    "\n",
    "print(\"--- 1. ê°€ìƒ í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ ---\")\n",
    "\n",
    "# --- 2. ëª¨ë¸ë¡œ ìœ ì‚¬ë„ ê³„ì‚° ---\n",
    "# (3.4 ë˜ëŠ” 3.7ì—ì„œ í•™ìŠµëœ 'model' ë³€ìˆ˜ë¥¼ ì‚¬ìš©)\n",
    "# (6ë²ˆ ì…€ì—ì„œ ì„í¬íŠ¸í•œ 'util' (from sentence_transformers import util)ì„ ì‚¬ìš©)\n",
    "\n",
    "print(\"--- 2. ì„ë² ë”© ë° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘... ---\")\n",
    "\n",
    "# ê° ë¬¸ì¥ ìŒì„ ì„ë² ë”©\n",
    "test_embeddings1 = model.encode([pair[0] for pair in test_pairs], convert_to_tensor=True)\n",
    "test_embeddings2 = model.encode([pair[1] for pair in test_pairs], convert_to_tensor=True)\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "similarities = []\n",
    "for emb1, emb2 in zip(test_embeddings1, test_embeddings2):\n",
    "    sim = util.cos_sim(emb1, emb2)\n",
    "    similarities.append(sim.item())\n",
    "\n",
    "print(f\"ê³„ì‚°ëœ ìœ ì‚¬ë„ ê°’: {np.round(similarities, 4)}\")\n",
    "print(f\"ì‹¤ì œ ì •ë‹µ ë ˆì´ë¸”: {ground_truth_labels}\")\n",
    "\n",
    "# --- 3. ìµœì ì˜ ì„ê³„ê°’ íƒìƒ‰ (F1-Score ê¸°ì¤€) ---\n",
    "\n",
    "print(\"--- 3. ìµœì ì˜ F1-Score ê¸°ì¤€ ì„ê³„ê°’ íƒìƒ‰ ì¤‘... ---\")\n",
    "\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "\n",
    "# 0.01ë¶€í„° 1.00ê¹Œì§€ 100ê°œì˜ ì„ê³„ê°’ í›„ë³´ë¥¼ í…ŒìŠ¤íŠ¸\n",
    "for threshold in [i * 0.01 for i in range(1, 101)]:\n",
    "    # í˜„ì¬ ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ (ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ 1, ì•„ë‹ˆë©´ 0)\n",
    "    preds = [1 if s > threshold else 0 for s in similarities]\n",
    "    \n",
    "    # F1-Score ê³„ì‚°\n",
    "    # (pos_label=1: '1'ì„ Positive í´ë˜ìŠ¤ë¡œ ê°„ì£¼ / zero_division=0: F1 ê³„ì‚° ë¶ˆê°€ ì‹œ 0ì  ì²˜ë¦¬)\n",
    "    f1 = f1_score(ground_truth_labels, preds, pos_label=1, zero_division=0)\n",
    "    \n",
    "    # ìµœê³  F1-Score ê°±ì‹ \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"\\n--- 4. íƒìƒ‰ ê²°ê³¼ ---\")\n",
    "print(f\"ìµœì ì˜ F1-Score: {best_f1:.4f}\")\n",
    "print(f\"ì´ë•Œì˜ ì„ê³„ê°’(Threshold): {best_threshold:.2f}\")\n",
    "\n",
    "# (ì°¸ê³ ) ë§Œì•½ F1-Scoreê°€ 0.0ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ë©´, \n",
    "# ë°ì´í„°ê°€ ë„ˆë¬´ ì ê±°ë‚˜(4ê°œ) ëª¨ë¸ì´ ì•„ì§ ì •ìƒ/ë‚šì‹œì„±ì„ êµ¬ë¶„í•˜ì§€ ëª»í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "# ì‹¤ì œ ìˆ˜ì²œ ê°œì˜ í‰ê°€ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•´ì•¼ ì˜ë¯¸ ìˆëŠ” ì„ê³„ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c45cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ì„ê³„ê°’(Threshold) 0.65 ì ìš© ì‹œ íŒì • ---\n",
      "í…ŒìŠ¤íŠ¸ 1 (ìœ ì‚¬ë„ 0.8070) íŒì •: [ì •ìƒ]\n",
      "í…ŒìŠ¤íŠ¸ 2 (ìœ ì‚¬ë„ 0.6899) íŒì •: [ì •ìƒ]\n"
     ]
    }
   ],
   "source": [
    "# 4.1ì˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ëŒ€í•´, 4.2ì—ì„œ ì°¾ì•˜ë‹¤ê³  'ê°€ì •í•œ' ì„ê³„ê°’ ì ìš©\n",
    "\n",
    "# (ì˜ˆì‹œ: ë§Œì•½ 4.2ì˜ ê³¼ì •ì„ í†µí•´ ìµœì ì˜ ì„ê³„ê°’ì´ 0.65ë¼ê³  ì°¾ì•˜ë‹¤ê³  ê°€ì •)\n",
    "THRESHOLD = 0.65 \n",
    "\n",
    "print(f\"--- ì„ê³„ê°’(Threshold) {THRESHOLD} ì ìš© ì‹œ íŒì • ---\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 1 íŒì •\n",
    "judgment_1 = '[ì •ìƒ]' if cos_sim_1 > THRESHOLD else '[ë‚šì‹œì„±]'\n",
    "print(f\"í…ŒìŠ¤íŠ¸ 1 (ìœ ì‚¬ë„ {cos_sim_1:.4f}) íŒì •: {judgment_1}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ 2 íŒì •\n",
    "judgment_2 = '[ì •ìƒ]' if cos_sim_2 > THRESHOLD else '[ë‚šì‹œì„±]'\n",
    "print(f\"í…ŒìŠ¤íŠ¸ 2 (ìœ ì‚¬ë„ {cos_sim_2:.4f}) íŒì •: {judgment_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c10cf",
   "metadata": {},
   "source": [
    "## 5ë‹¨ê³„: ìµœì¢… ì›Œí¬í”Œë¡œìš° ì ìš© (ê°œë…)\n",
    "ì´ì œ ì™„ì„±ëœ ë‘ ëª¨ë¸(KoBART, KoSimCSE)ì„ ì‚¬ìš©ìì˜ ìµœì¢… ì›Œí¬í”Œë¡œìš° 2.Cì— ì ìš©í•©ë‹ˆë‹¤.\n",
    "1. ì…ë ¥: ìƒˆë¡œìš´ ê¸°ì‚¬ [í—¤ë“œë¼ì¸ + ë³¸ë¬¸]ì´ ì…ë ¥ë©ë‹ˆë‹¤.\n",
    "2. ìš”ì•½: [ë³¸ë¬¸]ì„ íŒŒì¸íŠœë‹ëœ KoBART ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ [ìƒì„±ëœ ìš”ì•½ë¬¸]ì„ ì–»ìŠµë‹ˆë‹¤.\n",
    "3. ì„ë² ë”©: [í—¤ë“œë¼ì¸]ê³¼ [ìƒì„±ëœ ìš”ì•½ë¬¸]ì„ íŒŒì¸íŠœë‹ëœ KoSimCSE ëª¨ë¸(model.encode)ì— ë„£ì–´ ë‘ ê°œì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "4. ìœ ì‚¬ë„ ê³„ì‚°: ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„(util.cos_sim)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "5. íŒë³„: ì´ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ 4ë‹¨ê³„ì—ì„œ ì°¾ì€ **ì„ê³„ê°’(THRESHOLD)**ê³¼ ë¹„êµí•˜ì—¬ 'ì •ìƒ'/'ë‚šì‹œì„±' ì—¬ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤.\n",
    "6. ì—…ë°ì´íŠ¸: íŒë³„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì–¸ë¡ ì‚¬ì˜ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b2970",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
